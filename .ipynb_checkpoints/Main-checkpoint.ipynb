{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "#### Data Science Workflow\n",
    "An introduction and summary of the approach I took to complete this project\n",
    "#### Business Case and Business Value  \n",
    "Background  \n",
    "Goal  \n",
    "Why is this important?  \n",
    "#### Obtaining The Data\n",
    "Sourcing the data  \n",
    "Importing the CSVs  \n",
    "Importing packages  \n",
    "#### Scrubbing The Data\n",
    "DataCleaning.ipynb  \n",
    "#### Exploring The Data\n",
    "Use basic plots to visually examine relationships within the dataset  \n",
    "Exploration and familiarization with the dataset through statistical analysis  \n",
    "Detecting potential skews  \n",
    "Investigating features  \n",
    "#### Modeling The Data\n",
    "Train and test split the data  \n",
    "Model the data with a few classifiers and review results          \n",
    "Tune hyperparameters to find the ideal parameters for best performing models  \n",
    "Pickle final model\n",
    "#### Interpreting The Data\n",
    "Compare the models created and weigh the pros & cons    \n",
    "#### Conclusion\n",
    "Conclusion and opinion on my ideal model    \n",
    "Potential future work  \n",
    "References  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Workflow\n",
    "##### For this project I am going to use the OSEMiN process\n",
    "##### (Obtain, Scrub, Explore, Model, Interpret) \n",
    "\n",
    "- **Obtain** - The team and SPI data came from FiveThirtyEight's Soccer Predictions dataset, found [here](https://projects.fivethirtyeight.com/soccer-predictions/).\n",
    "- **Scrub** - The objective here is to identify errors, potential missing or corrupted fields in the data, and to clean up the dataset by discarding, replacing, or filling missing values and errors. \n",
    "- **Explore** - This is the EDA phase. The goal here is to understand patterns within our dataset by visualizing and testing to examine relationships in the data. \n",
    "- **Model** - This step encompases the higher level pre-processing such as normalization and managing class imbalance. After that we're ready to train some models to be able to give us some accurate predictive power to make intelligent business decisions. There are multiple steps of evaluation and refining of the models to ensure they're as accurate and unbiased as possible. \n",
    "- **Interpret** - In the final step, we examine our findings developed by our modeling and indentify important insights. As more data becomes available, this cycle can repeat and continue in a loop to build a faster, less biased, and more accurate model.\n",
    " \n",
    "Below you can follow the different stages of the EDA and modeling process by scrolling to the respective title."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Case\n",
    "#### Background\n",
    "Soccer is the most watched and bet-on sport in the world. With over 3 billion global fans and viewers, it dwarfs 2nd place Cricket by over 1 billion fans. The sports betting industry is worth an estimated $3 trillion, with soccer making up the largest share of that for a single sport. \n",
    "My goal is to predict the winner of a soccer match, using different features such as, Soccer Power Index (SPI), past performances and odds. With how many people bet on the sport daily, this could amount to be a popular and useful too to help gamblers get an edge on the house, and therefore reap higher returns on their bets. \n",
    "\n",
    "#### Overall Goal:  \n",
    "My goal is to predict the winner of a soccer match, using different features such as, Soccer Power Index (SPI), past performances and odds. With how many people bet on the sport daily, this could amount to be a popular and useful too to help gamblers get an edge on the house, and therefore reap higher returns on their bets. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Value  \n",
    "### Why is this important?\n",
    "The global sports gambling market is a multi-trillion-dollar industry, with much of that having to do with European club soccer. My target audience is the over 3 billion people who consider themselves soccer fans, and specifically the subset of that who intend to gamble their hard-earned money on it. I aim to assist these people in educating their decision-making to be able to maximize returns and profits on the bets that are placed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain the Data  \n",
    "I'm using SPI data and match data from FiveThirtyEight to model. I've preprocessed the data a bit in the notebook titled DataCleaning.ipynb. In this stage, I'll import the dataset and all the neccesary libraries for the whole process.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary tools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.legend_handler import HandlerBase\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "import itertools\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from scipy import stats\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report, \\\n",
    "    roc_curve, auc, mean_squared_error, roc_auc_score, recall_score, precision_score, \\\n",
    "    plot_confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "rng = np.random.RandomState(25)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rank</th>\n",
       "      <th>prev_rank</th>\n",
       "      <th>name</th>\n",
       "      <th>league</th>\n",
       "      <th>off</th>\n",
       "      <th>def</th>\n",
       "      <th>spi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>German Bundesliga</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.43</td>\n",
       "      <td>93.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>Barclays Premier League</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0.24</td>\n",
       "      <td>92.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Spanish Primera Division</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.50</td>\n",
       "      <td>90.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Barclays Premier League</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.46</td>\n",
       "      <td>88.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Paris Saint-Germain</td>\n",
       "      <td>French Ligue 1</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0.52</td>\n",
       "      <td>88.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  rank  prev_rank                 name                    league  \\\n",
       "0           0     1          1        Bayern Munich         German Bundesliga   \n",
       "1           1     2          2      Manchester City   Barclays Premier League   \n",
       "2           2     3          3            Barcelona  Spanish Primera Division   \n",
       "3           3     4          4            Liverpool   Barclays Premier League   \n",
       "4           4     5          5  Paris Saint-Germain            French Ligue 1   \n",
       "\n",
       "    off   def    spi  \n",
       "0  3.51  0.43  93.96  \n",
       "1  2.86  0.24  92.84  \n",
       "2  3.01  0.50  90.16  \n",
       "3  2.79  0.46  88.95  \n",
       "4  2.89  0.52  88.85  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "club_data = pd.read_csv('Data/SPI_data.csv')\n",
    "club_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'SPI_matches_all.csv' does not exist: b'SPI_matches_all.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9220a30eed31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmatch_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SPI_matches_all.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmatch_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'SPI_matches_all.csv' does not exist: b'SPI_matches_all.csv'"
     ]
    }
   ],
   "source": [
    "match_data = pd.read_csv('SPI_matches_all.csv')\n",
    "match_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrub and Explore the Data\n",
    "The data was tidied up in the DataCleaning.ipynb Notebook before being imported here. I will continue to tweak and pare the dataset while I explore it more and get ready to model. The line between scrubbing and exploring is blurry at best, and these two stages of the project flow occur simultaneously.  \n",
    "At the end of this section, the data will be prepared for the modeling phase and ready to be appropriately split.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "club_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "club_data = club_data.drop(columns=\"Unnamed: 0\")\n",
    "club_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_data = match_data.drop(columns=\"Unnamed: 0\")\n",
    "match_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the club data description\n",
    "plt.figure(figsize=(12,12))\n",
    "ax = sns.heatmap(club_data.describe().transpose(),\n",
    "           annot=True, linecolor=\"black\",\n",
    "            linewidth=1, square=True, vmin=0, vmax=1000, \n",
    "                 cmap=sns.color_palette(\"Set2\"))\n",
    "plt.title(\"Description Heatmap\")\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next I'll look at possible multicollinearity among the features\n",
    "correlation = match_data.corr()\n",
    "plt.figure(figsize=(30,30))\n",
    "ax = sns.heatmap(correlation, annot=True, \n",
    "                cmap=sns.color_palette(\"coolwarm\", 7),\n",
    "                linewidth=1, linecolor=\"white\")\n",
    "plt.title(\"Collinearity Between Features\")\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some redundant columns, and others that don't bring much meaningful information for modeling. I'll continue to pare down this dataset to a manageable level and reduce the number of features.  I want to reduce the number of features for selection in the final deployment so I will be removing all redundant columns, relative importances, NSXG, and all date/time related info.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "match_data_final = match_data[[\"league_id\", \"league\", \"team1\", \"team2\", \"spi1\", \"spi2\",\n",
    "                               \"prob1\", \"prob2\", \"probtie\", \"proj_score1\", \"proj_score2\", \n",
    "                               \"score1\", \"score2\", \"xg1\", \"xg2\"]].copy()\n",
    "match_data_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another look at collinearity \n",
    "sns.set(font_scale=1.7)\n",
    "correlation = match_data_final.corr()\n",
    "plt.figure(figsize=(30,30))\n",
    "ax = sns.heatmap(correlation, annot=True, \n",
    "                cmap=sns.color_palette(\"coolwarm\", 7),\n",
    "                linewidth=1, linecolor=\"white\")\n",
    "plt.title(\"Collinearity Between Features\")\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the close correlation between prob1, prob2 and their respective projected score, I'm going to drop the proj_score1 and proj_score2 columns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_data_final = match_data_final.drop(columns=[\"proj_score1\", \"proj_score2\"])\n",
    "match_data_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "match_data_final = match_data_final.drop(columns=\"league_id\")\n",
    "match_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all rows where the score and xg data is absent\n",
    "fullscore_data = match_data_final[match_data_final['score1'].notna()]\n",
    "fullscore_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to loop through df and assign target values\n",
    "# 0 = draw, 1 = team1(home) win, 2 = team2(away) win\n",
    "def make_target(df):\n",
    "    if df['score1'] == df['score2']:\n",
    "        return 0\n",
    "    elif df['score1'] > df['score2']:\n",
    "        return 1\n",
    "    elif df['score1'] < df['score2']:\n",
    "        return 2\n",
    "    else: \n",
    "        return 'Undefined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_data = fullscore_data.copy()\n",
    "multiclass_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_data['target'] = multiclass_data.apply(make_target, axis=1)\n",
    "multiclass_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_data.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_data = multiclass_data.drop(columns=\"league\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to XG(expected goal) data not being available before the match, I want to remove that as a feature. In the apps final state, I want to be able to prompt a user for: 2 clubs(the SPIs will be stored in a database), probability for Home win, Away win, and draw and create a prediction from that.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_data = multiclass_data.drop(columns=[\"xg1\",\"xg2\"])\n",
    "multiclass_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving this set as the training set for future use and saving the base multiclass_data \n",
    "# dataframe in case I make any mistakes and need to revert. \n",
    "training_data = multiclass_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data.drop(columns=[\"team1\", \"team2\"])\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "club_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations \n",
    "#### Target class counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I want to see how many instances of each class we have in the dataset \n",
    "plt.figure(figsize=(12,12))\n",
    "ax = sns.countplot(y = training_data.target, palette=\"pastel\",\n",
    "                  linewidth=1, edgecolor=\"black\")\n",
    "for i, j in enumerate(training_data[\"target\"].value_counts().values):\n",
    "    ax.text(.75, i, j, fontsize=26)\n",
    "plt.title(\"Count for target classes in dataset\")\n",
    "labels = [\"Draw\", \"Home Win\", \"Away Win\"]\n",
    "ax.set_yticklabels(labels)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the spread, it seems more likely the home team wins, and more likely a match ends with a clear winner than with a draw. \n",
    "\n",
    "#### Plotted distributions of all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"spi1\", \"spi2\", \"prob1\", \"prob2\", \"probtie\", \"score1\", \"score2\"]\n",
    "length  = len(columns)\n",
    "colors  = [\"r\",\"g\",\"b\",\"m\",\"y\",\"c\",\"k\"] \n",
    "\n",
    "plt.figure(figsize=(13,20))\n",
    "for i,j,k in itertools.zip_longest(columns,range(length),colors):\n",
    "    plt.subplot(length/2,length/2,j+1)\n",
    "    sns.distplot(training_data[i],color=k)\n",
    "    plt.title(i)\n",
    "    plt.subplots_adjust(hspace = .3)\n",
    "    plt.axvline(training_data[i].mean(),color = \"k\",linestyle=\"dashed\",label=\"MEAN\")\n",
    "    plt.axvline(training_data[i].std(),color = \"b\",linestyle=\"dotted\",label=\"STANDARD DEVIATION\")\n",
    "    plt.legend(loc=\"best\", prop={'size':12})\n",
    "    \n",
    "print (\"Plotting the distributions of features in dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly enough, SPI and prob1 seems to follow almost a normal distribution. Other than that, there's not much notable information to take from that. \n",
    "\n",
    "#### Boxplots for features related to target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [x for x in training_data.columns if x not in [\"target_class\"]]\n",
    "length  = len(columns)\n",
    "plt.figure(figsize=(13,20))\n",
    "for i,j in itertools.zip_longest(columns,range(length)):\n",
    "    plt.subplot(4,2,j+1)\n",
    "    plt.subplots_adjust(bottom = 1/50)\n",
    "    sns.lvplot(x=training_data[\"target\"],y=training_data[i],palette=\"pastel\")\n",
    "    plt.title(i + \" related to target\")\n",
    "    plt.subplots_adjust(hspace=.3)\n",
    "    plt.axhline(training_data[i].mean(),linestyle = \"dashed\",color =\"k\",label =\"Mean value for data\")\n",
    "    plt.legend(loc=\"upper left\", prop={'size':12})\n",
    "    \n",
    "print (\"Boxplots for features related to target_class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3d Plot showing how the pre-match probabilty corresponded to actual results\n",
    "- Purple = Draw\n",
    "- Pink = Home Win\n",
    "- Yellow = Away Win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = training_data\n",
    "\n",
    "fig = px.scatter_3d(df, y=training_data[\"prob1\"], x=training_data[\"prob2\"],\n",
    "                   z=training_data[\"probtie\"], color=training_data[\"target\"],\n",
    "                   labels={\n",
    "                       \"probtie\": \"Draw\",\n",
    "                       \"prob1\": \"Home Win\",\n",
    "                       \"prob2\": \"Away Win\"\n",
    "                   }, title= \"Predictions vs FT Result\")\n",
    "fig\n",
    "fig.show()\n",
    "\n",
    "#Purple = Draw\n",
    "#Pink = Home Win\n",
    "#Yellow = Away Win"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Summary \n",
    "By looking at the target class counts bar chart, we can clearly see there is a \n",
    "slight class imbalance. I think this is indicative of what people refer to as the \"home team advantage\".  \n",
    "\n",
    "For ease of end user use, I'll be paring down the features to SPI and odds. The SPI stat is already just a complex stat, it's easy to get a lot of information from that one number. I also opted to not use some of the other match data in the training set because of the concern of bleed. If the model is trained on information that it won't be able to get in realtime application, then it would be useless. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the Data\n",
    "In this section I'll use a variety of classifiers to create a a few models to see what performs best in this context. \"Best\" is going to be related to the model accuracy as a metric of success over the baseline 33% random guess.    \n",
    "\n",
    "#### First, I'll bring in a modeling function I wrote for a past project and instantiate the classifiers.\n",
    "I've commented out the roc curve due to multi-class not being supported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to combine classification report, confusion matrix, \n",
    "# accuracy score, roc curve, and auc in one easy way\n",
    "\n",
    "def model(algorithm, X_train, y_train, X_test, y_test, of_type):\n",
    "    algorithm.fit(X_train, y_train.astype(int))\n",
    "    preds = algorithm.predict(X_test)\n",
    "    \n",
    "    print(algorithm)\n",
    "    print(\"\\naccuracy_score:\",accuracy_score(y_test, preds))\n",
    "    print(\"\\nclassification report:\\n\", (classification_report(y_test, preds)))\n",
    "    \n",
    "    plt.figure(figsize=(14,10))\n",
    "    plt.subplot(221)\n",
    "    ax = sns.heatmap(confusion_matrix(y_test, preds), annot=True, fmt=\"d\", \n",
    "                linecolor=\"k\", linewidth=2)\n",
    "    # work around for top & bottom cutoff is pasted below\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    plt.title(\"Confusion Matrix\", fontsize=20)\n",
    "    \n",
    "    '''\n",
    "    predicting_probabilities = algorithm.predict_proba(X_test)[:,1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, predicting_probabilities)\n",
    "    plt.subplot(222)\n",
    "    plt.plot(fpr, tpr, label = (\"Area Under the Curve:\", auc(fpr, tpr)), color=\"r\")\n",
    "    plt.plot([1,0], [1,0], linestyle = \"dashed\", color=\"k\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(\"ROC Curve and Area Under Curve\", fontsize=20)\n",
    "    '''\n",
    "    \n",
    "    if of_type == \"feat\":\n",
    "        dataframe = pd.DataFrame(algorithm.feature_importances_, X_train.columns).reset_index()\n",
    "        dataframe = dataframe.rename(columns={\"index\":\"features\", 0:\"coefficients\"})\n",
    "        dataframe = dataframe.sort_values(by=\"coefficients\", ascending=False)\n",
    "        # plot conf_matrix, roc/auc, and feat importances\n",
    "        plt.subplot(223)\n",
    "        ax = sns.barplot(x = \"coefficients\", y = \"features\", data = dataframe, palette = \"husl\")\n",
    "        plt.title(\"Feature Importances\", fontsize=20)\n",
    "        for i, j in enumerate(dataframe[\"coefficients\"]):\n",
    "            ax.text(.011, i, j, weight = \"bold\")\n",
    "        \n",
    "    elif of_type == \"coef\":\n",
    "        dataframe = pd.DataFrame(algorithm.coef_.ravel(), X_train.columns).reset_index()\n",
    "        dataframe = dataframe.rename(columns={\"index\":\"features\", 0:\"coefficients\"})\n",
    "        dataframe = dataframe.sort_values(by=\"coefficients\", ascending=False)\n",
    "        # plot conf_matrix, roc/auc, and feat importances\n",
    "        plt.subplot(223)\n",
    "        ax = sns.barplot(x = \"coefficients\", y = \"features\", data = dataframe, palette = \"husl\")\n",
    "        plt.title(\"Feature Importances\", fontsize=20)\n",
    "        for i, j in enumerate(dataframe[\"coefficients\"]):\n",
    "            ax.text(.011, i, j, weight = \"bold\")\n",
    "            \n",
    "    elif of_type == \"none\":\n",
    "        return(algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating classifiers\n",
    "dt = DecisionTreeClassifier() # feat\n",
    "\n",
    "# K Nearest Neighbor\n",
    "knn = KNeighborsClassifier(n_neighbors=4) # none\n",
    "\n",
    "# Support Vector Machine\n",
    "# svc = svm.SVC(decision_function_shape='ovo')\n",
    "\n",
    "# Random Forest \n",
    "rf = RandomForestClassifier() # feat\n",
    "\n",
    "# XGBoost \n",
    "xgb = xgb.XGBClassifier(random_state=rng) # feat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''Commented out scaled/transformed data, as I opted to use\n",
    "   a random forest classifier which doesn't need scaled/normalized data.\n",
    "\n",
    "TNdata = training_data.copy()\n",
    "TNdata.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn's MinMaxScaler\n",
    "'''\n",
    "x = TNdata.values # returns a numpy array\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "TNdata = pd.DataFrame(x_scaled, columns = TNdata.columns)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''TNdata.head()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm the transformation didn't affect the target class\n",
    "'''TNdata.target.value_counts()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Splits\n",
    "Now to separate out the target class from the predictor variables and do a train-test split for both sets of data, and account for XGBoost. I've opted to do a 75/25 split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y of our datasets\n",
    "# the TNdata is the Transformed-Normalized set\n",
    "'''y_TN = TNdata['target']\n",
    "X_TN = TNdata.drop(columns=['target', 'score1', 'score2'], axis=1)'''\n",
    "\n",
    "y = training_data['target']\n",
    "X = training_data.drop(columns=['target', 'score1', 'score2'], axis=1)\n",
    "\n",
    "# random seed is already defined as the variable rng.\n",
    "\n",
    "# split data into the train and test sets\n",
    "'''X_train_TN, X_test_TN, y_train_TN, y_test_TN = train_test_split(X_TN, \n",
    "                                                    y_TN, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=rng)'''\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=rng)\n",
    "\n",
    "# split in numpy array format for XGBoost\n",
    "#X_train_xgb_TN, X_test_xgb_TN, y_train_xgb_TN, y_test_xgb_TN = train_test_split(X_TN.values, \n",
    "#                                                                    y_TN.values, \n",
    "#                                                                    test_size=0.25, \n",
    "#                                                                    random_state=rng)\n",
    "\n",
    "X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = train_test_split(X.values, \n",
    "                                                                    y.values, \n",
    "                                                                    test_size=0.25, \n",
    "                                                                    random_state=rng)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Accuracy \n",
    "\n",
    "I will first be comparing my model accuracy to the baseline of random choice. Disregarding odds, there's a 33% chance of choosing the correct match result. The minimum goal is to greatly improve from that, and the ideal goal is to improve from the bookmaker odds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data\n",
    "model(dt, X_train, y_train, X_test, y_test, \"feat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized data\n",
    "# model(dt, X_train_TN, y_train_TN, X_test, y_test, \"feat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data\n",
    "model(rf, X_train, y_train, X_test, y_test, \"feat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized data\n",
    "# model(rf, X_train_TN, y_train_TN, X_test, y_test, \"feat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data\n",
    "model(knn, X_train, y_train, X_test, y_test, \"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized data\n",
    "# model(knn, X_train_TN, y_train_TN, X_test, y_test, \"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing with non-normalized data\n",
    "clfxgb = XGBClassifier(random_state=rng)\n",
    "clfxgb.fit(X_train, y_train)\n",
    "training_preds = clfxgb.predict(X_train)\n",
    "val_preds = clfxgb.predict(X_test)\n",
    "training_accuracy = accuracy_score(y_train, training_preds)\n",
    "val_accuracy = accuracy_score(y_test, val_preds)\n",
    "\n",
    "print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw XGB\n",
    "model(clfxgb, X_train, y_train, X_test, y_test, \"feat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing with normalized data\n",
    "#clf = XGBClassifier(random_state=rng)\n",
    "#clf.fit(X_train_TN, y_train_TN)\n",
    "#training_preds = clf.predict(X_train)\n",
    "#val_preds = clf.predict(X_test)\n",
    "#training_accuracy = accuracy_score(y_train, training_preds)\n",
    "#val_accuracy = accuracy_score(y_test, val_preds)\n",
    "#\n",
    "#print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "#print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformed/normalized XGBoost\n",
    "#model(xgbo, X_train_TN, y_train_TN, X_test, y_test, \"feat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Models\n",
    "Due to their low levels of testing and validation accuracy, we clearly need to tune the models. The table below describes the performance of the models:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Classifier | Accuracy Score | Macro Avg. F1 Score | Weighted Avg. F1 score | False Pos | False Neg |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| XGBoost | 53 | .45 | .50 | 553 | 402 |\n",
    "| Random Forest | 51 | .45 | .49 | 522 | 477 |\n",
    "| Decision Tree | 43 | .40 | .43 | 539 | 628 |\n",
    "| KNN | 48 | .44 | .47 | 466 | 602 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Model Hyperparameters\n",
    "\n",
    "In this stage, I'll take the 4 models using the transformed/normalized data, and look to increase their performance via GridSearch to find the ideal parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch Optimization for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new KNN object\n",
    "knnTuned = KNeighborsClassifier()\n",
    "\n",
    "# hyperparameters to tune\n",
    "hyperparameters = {\n",
    "    'leaf_size' : [1, 10, 20, 30, 40, 50],\n",
    "    'n_neighbors' : [1, 20, 25, 35, 50],\n",
    "    'p' : [1, 2]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(knnTuned, hyperparameters, cv=10)\n",
    "\n",
    "# fit the model\n",
    "best_KNN = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Best leaf_size:', best_KNN.best_estimator_.get_params()\n",
    "      ['leaf_size'])\n",
    "print('Best p:', best_KNN.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_KNN.best_estimator_.get_params()\n",
    "      ['n_neighbors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_tuned = KNeighborsClassifier(leaf_size=1,\n",
    "                                n_neighbors=50,\n",
    "                                p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(KNN_tuned, X_train, y_train, X_test, y_test, \"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there was a 7% improvement over the un-tuned model, there's still a lot of room for improvement.  \n",
    "Since this is the best performing tuned model, I'm going to try tuning some more hyperparameters to see if we can make it perform a bit better before we move to deploy it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new KNN object\n",
    "knnFinal = KNeighborsClassifier()\n",
    "\n",
    "# hyperparameters to tune\n",
    "hyperparameters = {\n",
    "    'leaf_size' : [1, 10, 20],\n",
    "    'n_neighbors' : [1, 20, 35, 50],\n",
    "    'p' : [1, 2],\n",
    "    'weights' : ['uniform', 'distance'],\n",
    "    'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'metric' : ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(knnFinal, hyperparameters, cv=5)\n",
    "\n",
    "# fit the model\n",
    "knn_Final = clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Optimal Parameters: {knn_Final.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_Final = KNeighborsClassifier(leaf_size=1,\n",
    "                                n_neighbors=50,\n",
    "                                p=2,\n",
    "                                algorithm='auto',\n",
    "                                metric='manhattan',\n",
    "                                weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(KNN_Final, X_train, y_train, X_test, y_test, \"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch Optimization for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create new decision tree object\n",
    "dtTuned = DecisionTreeClassifier()\n",
    "\n",
    "# hyperparameters to tune\n",
    "hyperparameters = {\n",
    "    'min_samples_split' : [1, 10, 20, 30, 40],\n",
    "    'min_samples_leaf' : [1, 5, 10, 15, 20],\n",
    "    'max_depth' : [10, 25, 50, 65, 80, 100],\n",
    "    'criterion': ['gini','entropy'],\n",
    "    'class_weight' : [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(dtTuned, hyperparameters, cv=10)\n",
    "\n",
    "# fit the model\n",
    "best_DT = clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Optimal Parameters: {best_DT.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimized Decision Tree Hyperparameters:  \n",
    "- criterion: entropy\n",
    "- max depth: 10\n",
    "- min samples leaf: 1\n",
    "- min samples split: 40\n",
    "- class weight: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_Tuned = DecisionTreeClassifier(criterion='entropy',\n",
    "                                class_weight=None,\n",
    "                                max_depth=10,\n",
    "                                min_samples_leaf=1,\n",
    "                                min_samples_split=40,\n",
    "                                random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(dt_Tuned, X_train, y_train, X_test, y_test, \"feat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12% increase in accuracy from the un-tuned model However, there is still a high recall for the Home Win(1) class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch Optimization for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new random forest object\n",
    "rfTuned = RandomForestClassifier()\n",
    "\n",
    "# List hyperparameters to tune\n",
    "hyperparameters = {\n",
    "    'bootstrap' : [True, False],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'n_estimators' : [100, 200, 400, 600],\n",
    "    'max_features' : ['auto', 'sqrt'],\n",
    "    'max_depth' : [25, 50, 75, 100],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf' : [1, 2, 4]\n",
    "}\n",
    "# using stratified KFold crossvalidation\n",
    "clf = GridSearchCV(rfTuned, hyperparameters, cv=5)\n",
    "\n",
    "# fit the model\n",
    "best_RF = clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Optimal Parameters: {best_RF.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 50, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_Tuned = RandomForestClassifier(bootstrap=True, criterion='entropy',\n",
    "                                 max_depth=50, max_features='auto', \n",
    "                                 min_samples_leaf=4, min_samples_split=2, \n",
    "                                 n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(rf_Tuned, X_train, y_train, X_test, y_test, \"feat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not the best increase over the untuned model, only 2% accuracy. The forest model is still struggling with the Home Win(1) target class. This is probably due to it ranking the prob1 and prob2 pretty high, perhaps a boosted model will be able to account for that class imbalance a bit better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch Optimization for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new xgboost object\n",
    "xgbTuned = XGBClassifier()\n",
    "\n",
    "# List hyperparameters to tune\n",
    "hyperparameters = {\n",
    "    'max_depth': [3, 5, 10, 20],\n",
    "    'learning_rate': [0.05, 0.125, 0.25, 0.5, 1],\n",
    "    'subsample': [.5, .75, .9],\n",
    "    'min_child_weight': [1, 5, 10, 20],\n",
    "    'n_estimators': [10, 100, 500]\n",
    "}\n",
    "# using stratified KFold crossvalidation\n",
    "clf = GridSearchCV(xgbTuned, hyperparameters, scoring='accuracy', cv=5)\n",
    "\n",
    "# fit the model\n",
    "best_XGB = clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Optimal Parameters: {best_XGB.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_Tuned = XGBClassifier(random_state=rng, learning_rate=0.05, \n",
    "                         max_depth=3, min_child_weight=1,\n",
    "                         n_estimators=10, subsample=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(xgb_Tuned, X_train, y_train, X_test, y_test, \"feat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGBoost model will be discarded due to its poor ability to correctly predict draws. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle Final Tuned KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(KNN_Final, open('model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('model.sav', 'rb'))\n",
    "loaded_model"
   ]
  },
  {
   "attachments": {
    "KNNCM.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret the Data - Conclusion\n",
    "\n",
    "### Model Performance (Top 3 models, comparing metrics)\n",
    "| Classifier | Accuracy Score | Macro Avg. F1 Score | Weighted Avg. F1 score | False Pos | False Neg |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| KNN | 55 | .45 | .50 | 578 | 337 |\n",
    "| Decision Tree | 54 | .43 | .49 | 623 | 322 |\n",
    "| Random Forest | 53 | .45 | .50 | 545 | 407 |\n",
    "\n",
    "\n",
    "Overall, the models performance could be described as wildly mediocre. There was a 22% accuracy increase from our baseline model of equal guessing, but still not what I would consider a high level of accuracy. The main issue here, is that soccer is a very complex game, that is very difficult to describe in numbers - and often times, the numerically better team can still lose. \n",
    "\n",
    "### Final Thoughts - Future Work\n",
    "\n",
    "#### Model Selection\n",
    "I ended up selecting a K Nearest Neighbors model as my final model to deploy. The run-time for the tree based models made them less-than-ideal, and the XGBoost classifier was too biased and brought too many type 1 and 2 errors. In the future, I will experiment with using a neural network, as I think those types of algorithms could perform well with this type of data.\n",
    "![KNNCM.png](attachment:KNNCM.png)\n",
    "\n",
    "#### Business Value\n",
    "I tested the model on the UEFA Champions League Matchday 6 fixtures and it accurately predicted 6 of the 8 games. 75% accuracy in its first test is acceptable, especially given the complex context of sports betting. The fixtures it incorrectly predicted were \"upsets\", so there will need to be some more work done to account for those situations. I will continue to tune and test the model on games this winter and update this conclusion with my findings. \n",
    "\n",
    "#### Class Imbalance\n",
    "Going forward, I will do a second round of modeling where I address the class imbalance within the dataset. There was not a *huge* class imbalance, but I feel improvements on model accuracy could be made if they were accounted for, especially for some of the classifiers that are more sensitive to class imbalance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sources\n",
    "\n",
    "FiveThirtyEight's Soccer Predictions, found [here](https://projects.fivethirtyeight.com/soccer-predictions/).  \n",
    "Mohammad Ghahramanis Match datasets, found [here](https://data.world/analystmasters/earn-your-6-figure-prize-by-soccer-betting). \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondad6469289bf5c4ec9959ab1db2811e646"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
